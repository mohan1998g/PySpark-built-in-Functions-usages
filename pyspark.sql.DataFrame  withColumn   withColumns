pyspark.sql.DataFrame.withColumn

Returns a new DataFrame by adding a column or replacing the existing column that has the same name.

The column expression must be an expression over this DataFrame; attempting to add a column from some other DataFrame will raise an error.

Parameters
colName : str
          string, name of the new column.

col : Column
          a Column expression for the new column.

Returns : DataFrame
          DataFrame with new or replaced column.

Notes

This method introduces a projection internally. Therefore, calling it multiple times, for instance, via loops in order to add multiple columns can generate big plans which can cause performance issues and even StackOverflowException. To avoid this, use select() with multiple columns at once.

Examples

df = spark.createDataFrame([(2, "Alice"), (5, "Bob")], schema=["age", "name"])
df.withColumn('age2', df.age + 2).show()
+---+-----+----+
|age| name|age2|
+---+-----+----+
|  2|Alice|   4|
|  5|  Bob|   7|
+---+-----+----+

---------------------------------------------------------------------------------------------------------

pyspark.sql.DataFrame.withColumns

Returns a new DataFrame by adding multiple columns or replacing the existing columns that have the same names.

The colsMap is a map of column name and column, the column must only refer to attributes supplied by this Dataset. It is an error to add columns that refer to some other Dataset.

Parameters
colsMap : dict
        a dict of column name and Column. Currently, only a single map is supported.

Returns : DataFrame
        DataFrame with new or replaced columns.

Examples

df = spark.createDataFrame([(2, "Alice"), (5, "Bob")], schema=["age", "name"])
df.withColumns({'age2': df.age + 2, 'age3': df.age + 3}).show()
+---+-----+----+----+
|age| name|age2|age3|
+---+-----+----+----+
|  2|Alice|   4|   5|
|  5|  Bob|   7|   8|
+---+-----+----+----+
