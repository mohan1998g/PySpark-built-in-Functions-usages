pyspark.sql.functions.grouping

Aggregate function: indicates whether a specified column in a GROUP BY list is aggregated or not, returns 1 for aggregated or 0 for not aggregated in the result set.


Parameters
col : Column or str
          column to check if it’s aggregated.

Returns : Column
          returns 1 for aggregated or 0 for not aggregated in the result set.

Examples

df = spark.createDataFrame([("Alice", 2), ("Bob", 5)], ("name", "age"))

df.cube("name").agg(grouping("name"), sum("age")).orderBy("name").show()
+-----+--------------+--------+
| name|grouping(name)|sum(age)|
+-----+--------------+--------+
| NULL|             1|       7|
|Alice|             0|       2|
|  Bob|             0|       5|
+-----+--------------+--------+

---------------------------------------------------------------------------------------------------------------------------------------------------

pyspark.sql.functions.grouping_id

Aggregate function: returns the level of grouping, equals to

(grouping(c1) << (n-1)) + (grouping(c2) << (n-2)) + … + grouping(cn)

Parameters
cols : Column or str
          columns to check for.

Returns : Column
          returns level of the grouping it relates to.

Notes

The list of columns should match with grouping columns exactly, or empty (means all the grouping columns).

Examples

df = spark.createDataFrame([(1, "a", "a"),
                            (3, "a", "a"),
                            (4, "b", "c")], ["c1", "c2", "c3"])

df.cube("c2", "c3").agg(grouping_id(), sum("c1")).orderBy("c2", "c3").show()
+----+----+-------------+-------+
|  c2|  c3|grouping_id()|sum(c1)|
+----+----+-------------+-------+
|NULL|NULL|            3|      8|
|NULL|   a|            2|      4|
|NULL|   c|            2|      4|
|   a|NULL|            1|      4|
|   a|   a|            0|      4|
|   b|NULL|            1|      4|
|   b|   c|            0|      4|
+----+----+-------------+-------+
