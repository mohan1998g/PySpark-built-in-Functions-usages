pyspark.sql.functions.from_csv

Parses a column containing a CSV string to a row with the specified schema. Returns null, in the case of an unparseable string.

Parameters
col : Column or str
          a column or column name in CSV format

schema :class:`~pyspark.sql.Column` or str
          a column, or Python string literal with schema in DDL format, to use when parsing the CSV column.

options : dict, optional
          options to control parsing. accepts the same options as the CSV datasource. See Data Source Option for the version you use.

Returns : Column
          a column of parsed CSV values

Examples

data = [("1,2,3",)]
df = spark.createDataFrame(data, ("value",))

df.select(from_csv(df.value, "a INT, b INT, c INT").alias("csv")).collect()
[Row(csv=Row(a=1, b=2, c=3))]

value = data[0][0]

df.select(from_csv(df.value, schema_of_csv(value)).alias("csv")).collect()
[Row(csv=Row(_c0=1, _c1=2, _c2=3))]

data = [("   abc",)]
df = spark.createDataFrame(data, ("value",))

options = {'ignoreLeadingWhiteSpace': True}
df.select(from_csv(df.value, "s string", options).alias("csv")).collect()
[Row(csv=Row(s='abc'))]

---------------------------------------------------------------------------------------------------------------------------------------------------

pyspark.sql.functions.to_csv

Converts a column containing a StructType into a CSV string. Throws an exception, in the case of an unsupported type.

Parameters
col : Column or str
          name of column containing a struct.

options: dict, optional
          options to control converting. accepts the same options as the CSV datasource. See Data Source Option for the version you use.

Returns : Column
          a CSV string converted from given StructType.

Examples

from pyspark.sql import Row
data = [(1, Row(age=2, name='Alice'))]
df = spark.createDataFrame(data, ("key", "value"))

df.select(to_csv(df.value).alias("csv")).collect()
[Row(csv='2,Alice')]
