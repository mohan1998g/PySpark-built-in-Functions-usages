pyspark.sql.DataFrame.union

Return a new DataFrame containing the union of rows in this and another DataFrame.

Parameters
other : DataFrame
            Another DataFrame that needs to be unioned.

Returns : DataFrame
            A new DataFrame containing the combined rows with corresponding columns.

Notes

This method performs a SQL-style set union of the rows from both DataFrame objects, with no automatic deduplication of elements.

Use the distinct() method to perform deduplication of rows.

The method resolves columns by position (not by name), following the standard behavior in SQL.

Examples

Example 1: Combining two DataFrames with the same schema

df1 = spark.createDataFrame([(1, 'A'), (2, 'B')], ['id', 'value'])
df2 = spark.createDataFrame([(3, 'C'), (4, 'D')], ['id', 'value'])
df3 = df1.union(df2)
df3.show()
+---+-----+
| id|value|
+---+-----+
|  1|    A|
|  2|    B|
|  3|    C|
|  4|    D|
+---+-----+
Example 2: Combining two DataFrames with different schemas

from pyspark.sql.functions import lit
df1 = spark.createDataFrame([("Alice", 1), ("Bob", 2)], ["name", "id"])
df2 = spark.createDataFrame([(3, "Charlie"), (4, "Dave")], ["id", "name"])
df1 = df1.withColumn("age", lit(30))
df2 = df2.withColumn("age", lit(40))
df3 = df1.union(df2)  
df3.show()  
+-----+-------+---+
| name|     id|age|
+-----+-------+---+
|Alice|      1| 30|
|  Bob|      2| 30|
|    3|Charlie| 40|
|    4|   Dave| 40|
+-----+-------+---+
Example 3: Combining two DataFrames with mismatched columns

df1 = spark.createDataFrame([(1, 2)], ["A", "B"])
df2 = spark.createDataFrame([(3, 4)], ["C", "D"])
df3 = df1.union(df2)
df3.show()
+---+---+
|  A|  B|
+---+---+
|  1|  2|
|  3|  4|
+---+---+
Example 4: Combining duplicate rows from two different DataFrames

df1 = spark.createDataFrame([(1, 'A'), (2, 'B'), (3, 'C')], ['id', 'value'])
df2 = spark.createDataFrame([(3, 'C'), (4, 'D')], ['id', 'value'])
df3 = df1.union(df2).distinct().sort("id")
df3.show()
+---+-----+
| id|value|
+---+-----+
|  1|    A|
|  2|    B|
|  3|    C|
|  4|    D|
+---+-----+

-----------------------------------------------------------------------------------------------

pyspark.sql.DataFrame.unionAll

Return a new DataFrame containing the union of rows in this and another DataFrame.

Parameters
other : DataFrame
            Another DataFrame that needs to be combined

Returns : DataFrame
            A new DataFrame containing combined rows from both dataframes.

Notes

This method combines all rows from both DataFrame objects with no automatic deduplication of elements.

Use the distinct() method to perform deduplication of rows.

unionAll() is an alias to union()

--------------------------------------------------------------------------------------------------

pyspark.sql.DataFrame.unionByName

Returns a new DataFrame containing union of rows in this and another DataFrame.

This method performs a union operation on both input DataFrames, resolving columns by name (rather than position). When allowMissingColumns is True, missing columns will be filled with null.

Parameters
other : DataFrame
            Another DataFrame that needs to be combined.

allowMissingColumns : bool, optional, default False
            Specify whether to allow missing columns.

Returns : DataFrame
A new DataFrame containing the combined rows with corresponding columns of the two given DataFrames.

Examples

Example 1: Union of two DataFrames with same columns in different order.

df1 = spark.createDataFrame([[1, 2, 3]], ["col0", "col1", "col2"])
df2 = spark.createDataFrame([[4, 5, 6]], ["col1", "col2", "col0"])
df1.unionByName(df2).show()
+----+----+----+
|col0|col1|col2|
+----+----+----+
|   1|   2|   3|
|   6|   4|   5|
+----+----+----+
Example 2: Union with missing columns and setting allowMissingColumns=True.

df1 = spark.createDataFrame([[1, 2, 3]], ["col0", "col1", "col2"])
df2 = spark.createDataFrame([[4, 5, 6]], ["col1", "col2", "col3"])
df1.unionByName(df2, allowMissingColumns=True).show()
+----+----+----+----+
|col0|col1|col2|col3|
+----+----+----+----+
|   1|   2|   3|NULL|
|NULL|   4|   5|   6|
+----+----+----+----+
Example 3: Union of two DataFrames with few common columns.

df1 = spark.createDataFrame([[1, 2, 3]], ["col0", "col1", "col2"])
df2 = spark.createDataFrame([[4, 5, 6, 7]], ["col1", "col2", "col3", "col4"])
df1.unionByName(df2, allowMissingColumns=True).show()
+----+----+----+----+----+
|col0|col1|col2|col3|col4|
+----+----+----+----+----+
|   1|   2|   3|NULL|NULL|
|NULL|   4|   5|   6|   7|
+----+----+----+----+----+
Example 4: Union of two DataFrames with completely different columns.

df1 = spark.createDataFrame([[0, 1, 2]], ["col0", "col1", "col2"])
df2 = spark.createDataFrame([[3, 4, 5]], ["col3", "col4", "col5"])
df1.unionByName(df2, allowMissingColumns=True).show()
+----+----+----+----+----+----+
|col0|col1|col2|col3|col4|col5|
+----+----+----+----+----+----+
|   0|   1|   2|NULL|NULL|NULL|
|NULL|NULL|NULL|   3|   4|   5|
+----+----+----+----+----+----+
